import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime

# Danh s√°ch URL c·∫ßn qu√©t
URLS = [
    'https://easychair.org/cfp/',
    'https://easychair.org/cfp/random.cgi',
    'https://easychair.org/cfp/country.cgi?cc=ae',
    'https://easychair.org/cfp/country.cgi?cc=al',
    'https://easychair.org/cfp/country.cgi?cc=am',
    'https://easychair.org/cfp/country.cgi?cc=ao',
    'https://easychair.org/cfp/country.cgi?cc=ar',
    'https://easychair.org/cfp/country.cgi?cc=at',
    'https://easychair.org/cfp/country.cgi?cc=au',
    'https://easychair.org/cfp/country.cgi?cc=az',
    'https://easychair.org/cfp/country.cgi?cc=ba',
    'https://easychair.org/cfp/country.cgi?cc=bd',
    'https://easychair.org/cfp/country.cgi?cc=be',
    'https://easychair.org/cfp/country.cgi?cc=bf',
    'https://easychair.org/cfp/country.cgi?cc=bh',
    'https://easychair.org/cfp/country.cgi?cc=bj',
    'https://easychair.org/cfp/country.cgi?cc=bg',
    'https://easychair.org/cfp/country.cgi?cc=bn',
    'https://easychair.org/cfp/country.cgi?cc=br',
    'https://easychair.org/cfp/country.cgi?cc=bt',
    'https://easychair.org/cfp/country.cgi?cc=bw',
    'https://easychair.org/cfp/country.cgi?cc=ca',
    'https://easychair.org/cfp/country.cgi?cc=ch',
    'https://easychair.org/cfp/country.cgi?cc=cl',
    'https://easychair.org/cfp/country.cgi?cc=cn',
    'https://easychair.org/cfp/country.cgi?cc=co',
    'https://easychair.org/cfp/country.cgi?cc=cy',
    'https://easychair.org/cfp/country.cgi?cc=cz',
    'https://easychair.org/cfp/country.cgi?cc=de',
    'https://easychair.org/cfp/country.cgi?cc=dk',
    'https://easychair.org/cfp/country.cgi?cc=dz',
    'https://easychair.org/cfp/country.cgi?cc=ec',
    'https://easychair.org/cfp/country.cgi?cc=ee',
    'https://easychair.org/cfp/country.cgi?cc=eg',
    'https://easychair.org/cfp/country.cgi?cc=es',
    'https://easychair.org/cfp/country.cgi?cc=fi',
    'https://easychair.org/cfp/country.cgi?cc=fr',
    'https://easychair.org/cfp/country.cgi?cc=gb',
    'https://easychair.org/cfp/country.cgi?cc=ge',
    'https://easychair.org/cfp/country.cgi?cc=gr',
    'https://easychair.org/cfp/country.cgi?cc=hk',
    'https://easychair.org/cfp/country.cgi?cc=hn',
    'https://easychair.org/cfp/country.cgi?cc=hr',
    'https://easychair.org/cfp/country.cgi?cc=hu',
    'https://easychair.org/cfp/country.cgi?cc=id',
    'https://easychair.org/cfp/country.cgi?cc=ie',
    'https://easychair.org/cfp/country.cgi?cc=il',
    'https://easychair.org/cfp/country.cgi?cc=in',
    'https://easychair.org/cfp/country.cgi?cc=iq',
    'https://easychair.org/cfp/country.cgi?cc=ir',
    'https://easychair.org/cfp/country.cgi?cc=is',
    'https://easychair.org/cfp/country.cgi?cc=it',
    'https://easychair.org/cfp/country.cgi?cc=jo',
    'https://easychair.org/cfp/country.cgi?cc=jp',
    'https://easychair.org/cfp/country.cgi?cc=ke',
    'https://easychair.org/cfp/country.cgi?cc=kg',
    'https://easychair.org/cfp/country.cgi?cc=kh',
    'https://easychair.org/cfp/country.cgi?cc=kz',
    'https://easychair.org/cfp/country.cgi?cc=lk',
    'https://easychair.org/cfp/country.cgi?cc=lt',
    'https://easychair.org/cfp/country.cgi?cc=lu',
    'https://easychair.org/cfp/country.cgi?cc=lv',
    'https://easychair.org/cfp/country.cgi?cc=ma',
    'https://easychair.org/cfp/country.cgi?cc=me',
    'https://easychair.org/cfp/country.cgi?cc=mk',
    'https://easychair.org/cfp/country.cgi?cc=mn',
    'https://easychair.org/cfp/country.cgi?cc=mr',
    'https://easychair.org/cfp/country.cgi?cc=mu',
    'https://easychair.org/cfp/country.cgi?cc=mx',
    'https://easychair.org/cfp/country.cgi?cc=my',
    'https://easychair.org/cfp/country.cgi?cc=ng',
    'https://easychair.org/cfp/country.cgi?cc=nl',
    'https://easychair.org/cfp/country.cgi?cc=no',
    'https://easychair.org/cfp/country.cgi?cc=np',
    'https://easychair.org/cfp/country.cgi?cc=nz',
    'https://easychair.org/cfp/country.cgi?cc=om',
    'https://easychair.org/cfp/country.cgi?cc=pa',
    'https://easychair.org/cfp/country.cgi?cc=pe',
    'https://easychair.org/cfp/country.cgi?cc=ph',
    'https://easychair.org/cfp/country.cgi?cc=pk',
    'https://easychair.org/cfp/country.cgi?cc=pl',
    'https://easychair.org/cfp/country.cgi?cc=pt',
    'https://easychair.org/cfp/country.cgi?cc=qa',
    'https://easychair.org/cfp/country.cgi?cc=ra',
    'https://easychair.org/cfp/country.cgi?cc=ro',
    'https://easychair.org/cfp/country.cgi?cc=rs',
    'https://easychair.org/cfp/country.cgi?cc=ru',
    'https://easychair.org/cfp/country.cgi?cc=rw',
    'https://easychair.org/cfp/country.cgi?cc=sa',
    'https://easychair.org/cfp/country.cgi?cc=se',
    'https://easychair.org/cfp/country.cgi?cc=sg',
    'https://easychair.org/cfp/country.cgi?cc=si',
    'https://easychair.org/cfp/country.cgi?cc=sm',
    'https://easychair.org/cfp/country.cgi?cc=th',
    'https://easychair.org/cfp/country.cgi?cc=tn',
    'https://easychair.org/cfp/country.cgi?cc=tw',
    'https://easychair.org/cfp/country.cgi?cc=tz',
    'https://easychair.org/cfp/country.cgi?cc=ua',
    'https://easychair.org/cfp/country.cgi?cc=ug',
    'https://easychair.org/cfp/country.cgi?cc=us',
    'https://easychair.org/cfp/country.cgi?cc=uy',
    'https://easychair.org/cfp/country.cgi?cc=uz',
    'https://easychair.org/cfp/country.cgi?cc=vn',
    'https://easychair.org/cfp/country.cgi?cc=ye',
    'https://easychair.org/cfp/country.cgi?cc=zw'
]

# API v√† headers
API_URL = 'https://api.rpa.asia/api_research.php'
HEADERS = {'Content-Type': 'application/json'}

def parse_date(date_str):
    """Chuy·ªÉn ƒë·ªïi ƒë·ªãnh d·∫°ng ng√†y t·ª´ 'MMM DD, YYYY' sang 'YYYY-MM-DD'"""
    try:
        return datetime.strptime(date_str, '%b %d, %Y').strftime('%Y-%m-%d')
    except ValueError:
        return date_str  # Gi·ªØ nguy√™n n·∫øu kh√¥ng parse ƒë∆∞·ª£c

def get_current_time():
    """L·∫•y th·ªùi gian hi·ªán t·∫°i ƒë·ªãnh d·∫°ng YYYY-MM-DD HH:MM:SS"""
    return datetime.now().strftime('%Y-%m-%d %H:%M:%S')

# ================== H√†m l·∫•y topics chi ti·∫øt ==================
def scrape_topics(conf_url):
    """Truy c·∫≠p trang conference v√† l·∫•y danh s√°ch topics"""
    print(f"   üîç L·∫•y topics t·ª´ {conf_url}...")
    try:
        response = requests.get(conf_url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')

        # T√¨m header c√≥ ch·ª©a t·ª´ kh√≥a li√™n quan ƒë·∫øn topics
        headers = soup.find_all(['h2', 'h3', 'h4'])
        topics_section = None
        for h in headers:
            text = h.get_text(strip=True).lower()
            if any(keyword in text for keyword in ["topic", "scope", "call for papers"]):
                topics_section = h
                break

        topics = []
        if topics_section:
            # L·∫•y n·ªôi dung ngay sau header
            content = []
            next_tag = topics_section.find_next_sibling()
            while next_tag and next_tag.name in ["p", "ul", "ol", "div"]:
                content.append(next_tag.get_text(" ", strip=True))
                next_tag = next_tag.find_next_sibling()
            topics_text = " ".join(content)
            # C·∫Øt th√†nh list theo d·∫•u ph·∫©y
            topics = [t.strip() for t in topics_text.replace("\n", " ").split(",") if t.strip()]

        return topics
    except Exception as e:
        print(f"   ‚ö†Ô∏è L·ªói khi l·∫•y topics t·ª´ {conf_url}: {e}")
        return []

# ================== H√†m scrape country ==================
def scrape_url(url):
    """Qu√©t d·ªØ li·ªáu t·ª´ m·ªôt URL EasyChair country"""
    print(f"üöÄ Qu√©t d·ªØ li·ªáu t·ª´ {url}...")
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        rows = soup.select('table tbody tr')
        print(f"‚úÖ T√¨m th·∫•y {len(rows)} h√†ng t·∫°i {url}.")

        data = []
        base_url = 'https://easychair.org'

        for i, row in enumerate(rows, start=1):
            try:
                print(f"üîπ H√†ng {i}/{len(rows)} t·∫°i {url}...", end="\r")
                cols = row.find_all('td')
                if len(cols) >= 6:
                    acronym = cols[0].text.strip()
                    name = cols[1].text.strip()
                    location = cols[2].text.strip()
                    deadline = parse_date(cols[3].text.strip())
                    start_date = parse_date(cols[4].text.strip())

                    # L·∫•y topics t·ª´ country page
                    topic_cell = cols[5]
                    badges = topic_cell.find_all('span', class_='badge')
                    if badges:
                        topics = [e.text.strip() for e in badges]
                    else:
                        topics = [t.strip() for t in topic_cell.get_text(separator=",").split(",") if t.strip()]

                    # L·∫•y link chi ti·∫øt h·ªôi ngh·ªã
                    url_link = cols[0].find('a', href=True)
                    conf_url = url_link['href'] if url_link else ''
                    if conf_url and not conf_url.startswith('http'):
                        conf_url = base_url + conf_url

                    # N·∫øu c√≥ conf_url th√¨ scrape th√™m topics chi ti·∫øt
                    extra_topics = scrape_topics(conf_url) if conf_url else []
                    all_topics = topics + extra_topics

                    data.append({
                        'acronym': acronym,
                        'name': name,
                        'location': location,
                        'deadline': deadline,
                        'start_date': start_date,
                        'topics': ", ".join(sorted(set(all_topics))),
                        'url': conf_url
                    })
            except Exception as e:
                print(f"\n‚ö†Ô∏è L·ªói t·∫°i h√†ng {i} c·ªßa {url}: {e}")
        return data
    except Exception as e:
        print(f"\n‚ö†Ô∏è L·ªói khi qu√©t {url}: {e}")
        return []

# Thu th·∫≠p d·ªØ li·ªáu t·ª´ t·∫•t c·∫£ URL v√† lo·∫°i b·ªè tr√πng l·∫∑p
print("üöÄ B·∫Øt ƒë·∫ßu c√†o d·ªØ li·ªáu t·ª´ t·∫•t c·∫£ URL...")
all_data = []
seen = set()  # L∆∞u tr·ªØ c√°c b·∫£n ghi ƒë√£ th·∫•y ƒë·ªÉ lo·∫°i b·ªè tr√πng l·∫∑p
for url in URLS:
    data = scrape_url(url)
    for record in data:
        key = (record['acronym'], record['start_date'])
        if key not in seen:
            seen.add(key)
            all_data.append(record)
print(f"\n‚úÖ Thu th·∫≠p ƒë∆∞·ª£c {len(all_data)} b·∫£n ghi duy nh·∫•t.")

# Ki·ªÉm tra d·ªØ li·ªáu hi·ªán c√≥ b·∫±ng GET
print("\nüì° Ki·ªÉm tra d·ªØ li·ªáu hi·ªán c√≥ trong c∆° s·ªü d·ªØ li·ªáu...")
existing_conferences = {}
try:
    response = requests.get(API_URL, headers=HEADERS, timeout=10)
    if response.status_code == 200:
        try:
            existing_data = response.json()
            for conf in existing_data:
                key = (conf['acronym'], conf['start_date'])
                existing_conferences[key] = conf['id_conference']
            print(f"‚úÖ T√¨m th·∫•y {len(existing_conferences)} h·ªôi th·∫£o trong c∆° s·ªü d·ªØ li·ªáu.")
        except ValueError:
            print(f"‚ö†Ô∏è Ph·∫£n h·ªìi GET kh√¥ng ph·∫£i JSON: {response.text}")
    else:
        print(f"‚ö†Ô∏è L·ªói GET {response.status_code}: {response.text}")
except Exception as e:
    print(f"‚ö†Ô∏è L·ªói khi g·ª≠i y√™u c·∫ßu GET: {e}")

# Ph√¢n lo·∫°i b·∫£n ghi: th√™m m·ªõi (POST) ho·∫∑c c·∫≠p nh·∫≠t (PUT)
records_to_post = []
records_to_put = []
current_time = get_current_time()
for record in all_data:
    key = (record['acronym'], record['start_date'])
    if key in existing_conferences:
        record['id_conference'] = existing_conferences[key]
        record['modified_time'] = current_time  # Th√™m modified_time cho PUT
        records_to_put.append(record)
    else:
        record['created_time'] = current_time  # Th√™m created_time cho POST
        record['modified_time'] = current_time  # Th√™m modified_time cho POST
        records_to_post.append(record)

# G·ª≠i d·ªØ li·ªáu m·ªõi qua POST
success_count = 0
batch_size = 50

if records_to_post:
    print("\nüì§ G·ª≠i d·ªØ li·ªáu m·ªõi ƒë·∫øn API (POST)...")
    for i in range(0, len(records_to_post), batch_size):
        batch = records_to_post[i:i + batch_size]
        try:
            response = requests.post(API_URL, json=batch, headers=HEADERS, timeout=10)
            if response.status_code == 200:
                try:
                    response_data = response.json()
                    for j, result in enumerate(response_data.get('results', [])):
                        record = batch[j]
                        if result.get('message') == "Th√™m h·ªôi th·∫£o th√†nh c√¥ng":
                            success_count += 1
                            print(f"  üîπ B·∫£n ghi {i + j + 1}/{len(all_data)} - {record['acronym']}: Th√™m th√†nh c√¥ng. ID: {result.get('id_conference')}")
                        elif result.get('message') == "H·ªôi th·∫£o ƒë√£ t·ªìn t·∫°i":
                            print(f"  üîπ B·∫£n ghi {i + j + 1}/{len(all_data)} - {record['acronym']}: ƒê√£ t·ªìn t·∫°i. ID: {result.get('id_conference')}")
                            record['id_conference'] = result.get('id_conference')
                            record['modified_time'] = current_time
                            records_to_put.append(record)
                        else:
                            print(f"  üîπ B·∫£n ghi {i + j + 1}/{len(all_data)} - {record['acronym']}: L·ªói: {result.get('error')}")
                    print(f"‚úÖ L√¥ {i//batch_size + 1} ({len(batch)} b·∫£n ghi): X·ª≠ l√Ω th√†nh c√¥ng.")
                except ValueError:
                    print(f"  ‚ö†Ô∏è Ph·∫£n h·ªìi API kh√¥ng ph·∫£i JSON: {response.text}")
            else:
                print(f"‚ùå L√¥ {i//batch_size + 1} ({len(batch)} b·∫£n ghi): L·ªói {response.status_code} - {response.text}")
                for j, record in enumerate(batch):
                    print(f"  üîπ B·∫£n ghi {i + j + 1}/{len(all_data)} - {record['acronym']}: Th·∫•t b·∫°i.")
        except Exception as e:
            print(f"‚ùå L√¥ {i//batch_size + 1} ({len(batch)} b·∫£n ghi): L·ªói khi g·ª≠i: {e}")
            for j, record in enumerate(batch):
                print(f"  üîπ B·∫£n ghi {i + j + 1}/{len(all_data)} - {record['acronym']}: Th·∫•t b·∫°i.")

# G·ª≠i d·ªØ li·ªáu c·∫≠p nh·∫≠t qua PUT
if records_to_put:
    print("\nüì§ G·ª≠i d·ªØ li·ªáu c·∫≠p nh·∫≠t ƒë·∫øn API (PUT)...")
    for i in range(0, len(records_to_put), batch_size):
        batch = records_to_put[i:i + batch_size]
        # Lo·∫°i b·ªè created_time kh·ªèi payload PUT ƒë·ªÉ tr√°nh ghi ƒë√®
        batch_for_put = [
            {k: v for k, v in record.items() if k != 'created_time'}
            for record in batch
        ]
        try:
            response = requests.put(API_URL, json=batch_for_put, headers=HEADERS, timeout=10)
            if response.status_code == 200:
                try:
                    response_data = response.json()
                    for j, result in enumerate(response_data.get('results', [])):
                        record = batch[j]
                        if result.get('message') == "C·∫≠p nh·∫≠t h·ªôi th·∫£o th√†nh c√¥ng":
                            success_count += 1
                            print(f"  üîπ B·∫£n ghi {i + j + 1}/{len(records_to_put)} - {record['acronym']}: C·∫≠p nh·∫≠t th√†nh c√¥ng.")
                        else:
                            print(f"  üîπ B·∫£n ghi {i + j + 1}/{len(records_to_put)} - {record['acronym']}: L·ªói: {result.get('error')}")
                    print(f"‚úÖ L√¥ {i//batch_size + 1} ({len(batch)} b·∫£n ghi): C·∫≠p nh·∫≠t th√†nh c√¥ng.")
                except ValueError:
                    print(f"  ‚ö†Ô∏è Ph·∫£n h·ªìi API kh√¥ng ph·∫£i JSON: {response.text}")
            else:
                print(f"‚ùå L√¥ {i//batch_size + 1} ({len(batch)} b·∫£n ghi): L·ªói {response.status_code} - {response.text}")
                for j, record in enumerate(batch):
                    print(f"  üîπ B·∫£n ghi {i + j + 1}/{len(records_to_put)} - {record['acronym']}: Th·∫•t b·∫°i.")
        except Exception as e:
            print(f"‚ùå L√¥ {i//batch_size + 1} ({len(batch)} b·∫£n ghi): L·ªói khi g·ª≠i: {e}")
            for j, record in enumerate(batch):
                print(f"  üîπ B·∫£n ghi {i + j + 1}/{len(records_to_put)} - {record['acronym']}: Th·∫•t b·∫°i.")

# X·ª≠ l√Ω x√≥a (n·∫øu c√≥)
records_to_delete = []  # ƒê·ªÉ tr·ªëng theo y√™u c·∫ßu
if records_to_delete:
    print("\nüì§ G·ª≠i y√™u c·∫ßu x√≥a ƒë·∫øn API (DELETE)...")
    for i in range(0, len(records_to_delete), batch_size):
        batch = records_to_delete[i:i + batch_size]
        try:
            response = requests.delete(API_URL, json=batch, headers=HEADERS, timeout=10)
            if response.status_code == 200:
                try:
                    response_data = response.json()
                    for j, result in enumerate(response_data.get('results', [])):
                        record = batch[j]
                        if result.get('message') == "X√≥a h·ªôi th·∫£o th√†nh c√¥ng":
                            success_count += 1
                            print(f"  üîπ B·∫£n ghi {i + j + 1}/{len(records_to_delete)} - {record['acronym']}: X√≥a th√†nh c√¥ng.")
                        else:
                            print(f"  üîπ B·∫£n ghi {i + j + 1}/{len(records_to_delete)} - {record['acronym']}: L·ªói: {result.get('error')}")
                    print(f"‚úÖ L√¥ {i//batch_size + 1} ({len(batch)} b·∫£n ghi): X√≥a th√†nh c√¥ng.")
                except ValueError:
                    print(f"  ‚ö†Ô∏è Ph·∫£n h·ªìi API kh√¥ng ph·∫£i JSON: {response.text}")
            else:
                print(f"‚ùå L√¥ {i//batch_size + 1} ({len(batch)} b·∫£n ghi): L·ªói {response.status_code} - {response.text}")
                for j, record in enumerate(batch):
                    print(f"  üîπ B·∫£n ghi {i + j + 1}/{len(records_to_delete)} - {record['acronym']}: Th·∫•t b·∫°i.")
        except Exception as e:
            print(f"‚ùå L√¥ {i//batch_size + 1} ({len(batch)} b·∫£n ghi): L·ªói khi g·ª≠i: {e}")
            for j, record in enumerate(batch):
                print(f"  üîπ B·∫£n ghi {i + j + 1}/{len(records_to_delete)} - {record['acronym']}: Th·∫•t b·∫°i.")

print(f"\nüèÅ Ho√†n t·∫•t! ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng {success_count}/{len(all_data)} b·∫£n ghi.")